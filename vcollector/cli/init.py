"""
Init CLI handler.

Handles: vcollector init

Bootstraps a fresh VelocityCollector environment:
- Creates ~/.vcollector directory structure
- Initializes config.yaml with defaults
- Creates dcim.db with schema and default platforms
- Creates collector.db with schema (jobs, credentials, vault)
- Optionally creates tfsm_templates.db
"""

import sys
from pathlib import Path
from typing import Optional

from vcollector.core.config import Config, get_config


def handle_init(args) -> int:
    """Handle init subcommand."""

    base_dir = Path(args.dir).expanduser() if args.dir else Path.home() / ".vcollector"
    force = getattr(args, 'force', False)
    skip_defaults = getattr(args, 'no_defaults', False)

    print(f"Initializing VelocityCollector in: {base_dir}\n")

    # Check if already initialized
    if base_dir.exists() and not force:
        config_file = base_dir / "config.yaml"
        dcim_db = base_dir / "dcim.db"
        collector_db = base_dir / "collector.db"

        existing = []
        if config_file.exists():
            existing.append("config.yaml")
        if dcim_db.exists():
            existing.append("dcim.db")
        if collector_db.exists():
            existing.append("collector.db")

        if existing:
            print(f"Already initialized. Found: {', '.join(existing)}")
            print("Use --force to reinitialize (WARNING: databases will be reset)")
            return 1

    try:
        # 1. Create directory structure
        print("Creating directories...")
        _create_directories(base_dir)

        # 2. Create config.yaml
        print("Creating config.yaml...")
        _create_config(base_dir, force)

        # 3. Initialize DCIM database
        print("Initializing dcim.db...")
        _init_dcim_db(base_dir, include_defaults=not skip_defaults)

        # 4. Initialize Collector database
        print("Initializing collector.db...")
        _init_collector_db(base_dir)

        # 5. Initialize TextFSM templates database (optional)
        if not args.skip_tfsm:
            print("Initializing tfsm_templates.db...")
            _init_tfsm_db(base_dir)

        print()
        print("=" * 60)
        print("✓ VelocityCollector initialized successfully!")
        print("=" * 60)
        print()
        print("Next steps:")
        print()
        print("  1. Initialize the credential vault:")
        print("     vcollector vault init")
        print()
        print("  2. Add SSH credentials:")
        print("     vcollector vault add lab --username admin")
        print()
        print("  3. Add devices (GUI or import):")
        print("     vcollector gui")
        print("     # Or import from CSV/NetBox")
        print()
        print("  4. Create a collection job:")
        print("     vcollector jobs create --vendor arista --type arp")
        print()
        print("  5. Run collection:")
        print("     vcollector run --job arista-arp")
        print()
        print(f"Configuration: {base_dir / 'config.yaml'}")
        print(f"Databases:     {base_dir}")

        return 0

    except Exception as e:
        print(f"\n✗ Initialization failed: {e}")
        return 1


def _create_directories(base_dir: Path):
    """Create required directory structure."""
    directories = [
        base_dir,
        base_dir / "collections",
        base_dir / "jobs",
        base_dir / "logs",
    ]

    for d in directories:
        d.mkdir(parents=True, exist_ok=True)
        print(f"  ✓ {d}")


def _create_config(base_dir: Path, force: bool = False):
    """Create config.yaml with defaults."""
    config_file = base_dir / "config.yaml"

    if config_file.exists() and not force:
        print(f"  - {config_file} (exists, skipping)")
        return

    config_content = f"""\
# VelocityCollector Configuration
# Generated by 'vcollector init'

# =============================================================================
# Database Paths
# =============================================================================

# Device inventory database (NetBox-compatible schema)
dcim_db: {base_dir / 'dcim.db'}

# Collector database (jobs, credentials, history)
collector_db: {base_dir / 'collector.db'}

# TextFSM template database
tfsm_templates_db: {base_dir / 'tfsm_templates.db'}

# =============================================================================
# Storage Paths
# =============================================================================

# Where captured output is stored
collections_dir: {base_dir / 'collections'}

# Legacy JSON job files (for backward compatibility)
legacy_jobs_dir: {base_dir / 'jobs'}

# =============================================================================
# Default Execution Settings
# =============================================================================
# These are used when a job doesn't specify its own values

execution:
  max_workers: 12          # Concurrent SSH connections per job
  timeout: 60              # SSH timeout in seconds
  inter_command_delay: 1   # Seconds between commands

# =============================================================================
# Logging
# =============================================================================

logging:
  level: INFO              # DEBUG, INFO, WARNING, ERROR
  file: {base_dir / 'logs' / 'vcollector.log'}
"""

    config_file.write_text(config_content)
    print(f"  ✓ {config_file}")


def _init_dcim_db(base_dir: Path, include_defaults: bool = True):
    """Initialize DCIM database with schema."""
    from vcollector.dcim.db_schema import DCIMDatabase

    db_path = base_dir / "dcim.db"

    db = DCIMDatabase(db_path)
    created = db.init_schema(include_defaults=include_defaults)

    if created:
        print(f"  ✓ {db_path}")
        if include_defaults:
            # Count what was created
            cursor = db.conn.cursor()
            mfg_count = cursor.execute("SELECT COUNT(*) FROM dcim_manufacturer").fetchone()[0]
            plat_count = cursor.execute("SELECT COUNT(*) FROM dcim_platform").fetchone()[0]
            role_count = cursor.execute("SELECT COUNT(*) FROM dcim_device_role").fetchone()[0]
            print(f"    - {mfg_count} manufacturers")
            print(f"    - {plat_count} platforms (with netmiko mappings)")
            print(f"    - {role_count} device roles")
    else:
        print(f"  - {db_path} (schema exists)")

    db.close()


def _init_collector_db(base_dir: Path):
    """Initialize Collector database with schema."""
    import sqlite3

    db_path = base_dir / "collector.db"

    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()

    # Check if already initialized
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='jobs'
    """)

    if cursor.fetchone() is not None:
        print(f"  - {db_path} (schema exists)")
        conn.close()
        return

    # Create schema
    schema = """
    -- Credentials table (vault)
    CREATE TABLE IF NOT EXISTS credentials (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT UNIQUE NOT NULL,
        username TEXT NOT NULL,
        password_encrypted TEXT,
        ssh_key_encrypted TEXT,
        ssh_key_passphrase_encrypted TEXT,
        is_default INTEGER DEFAULT 0,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
    );

    CREATE INDEX IF NOT EXISTS idx_credentials_name ON credentials(name);
    CREATE INDEX IF NOT EXISTS idx_credentials_default ON credentials(is_default);

    -- Vault metadata (encryption salt, etc.)
    CREATE TABLE IF NOT EXISTS vault_metadata (
        id INTEGER PRIMARY KEY,
        key TEXT UNIQUE NOT NULL,
        value TEXT
    );

    -- Jobs table
    CREATE TABLE IF NOT EXISTS jobs (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT NOT NULL,
        slug TEXT UNIQUE NOT NULL,
        description TEXT,
        capture_type TEXT NOT NULL,
        vendor TEXT,
        credential_id INTEGER,
        credential_fallback_env TEXT,
        protocol TEXT NOT NULL DEFAULT 'ssh',
        device_filter_source TEXT DEFAULT 'database',
        device_filter_platform_id INTEGER,
        device_filter_site_id INTEGER,
        device_filter_role_id INTEGER,
        device_filter_name_pattern TEXT,
        device_filter_status TEXT DEFAULT 'active',
        paging_disable_command TEXT,
        command TEXT NOT NULL,
        output_directory TEXT,
        filename_pattern TEXT DEFAULT '{device_name}.txt',
        use_textfsm INTEGER DEFAULT 0,
        textfsm_template TEXT,
        validation_min_score INTEGER DEFAULT 0,
        store_failures INTEGER DEFAULT 1,
        max_workers INTEGER DEFAULT 10,
        timeout_seconds INTEGER DEFAULT 60,
        inter_command_delay INTEGER DEFAULT 1,
        base_path TEXT DEFAULT '~/.vcollector/collections',
        schedule_enabled INTEGER DEFAULT 0,
        schedule_cron TEXT,
        is_enabled INTEGER DEFAULT 1,
        last_run_at TEXT,
        last_run_status TEXT,
        legacy_job_id INTEGER,
        legacy_job_file TEXT,
        migrated_at TEXT,
        created_at TEXT NOT NULL DEFAULT (datetime('now')),
        updated_at TEXT NOT NULL DEFAULT (datetime('now')),
        FOREIGN KEY (credential_id) REFERENCES credentials(id) ON DELETE SET NULL
    );

    CREATE INDEX IF NOT EXISTS idx_jobs_capture_type ON jobs(capture_type);
    CREATE INDEX IF NOT EXISTS idx_jobs_vendor ON jobs(vendor);
    CREATE INDEX IF NOT EXISTS idx_jobs_enabled ON jobs(is_enabled);
    CREATE INDEX IF NOT EXISTS idx_jobs_legacy_id ON jobs(legacy_job_id);

    -- Job commands (multi-command jobs)
    CREATE TABLE IF NOT EXISTS job_commands (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        job_id INTEGER NOT NULL,
        sequence INTEGER NOT NULL DEFAULT 0,
        command TEXT NOT NULL,
        description TEXT,
        output_directory TEXT,
        use_textfsm INTEGER DEFAULT 0,
        textfsm_template TEXT,
        FOREIGN KEY (job_id) REFERENCES jobs(id) ON DELETE CASCADE,
        UNIQUE (job_id, sequence)
    );

    CREATE INDEX IF NOT EXISTS idx_job_commands_job ON job_commands(job_id);

    -- Job tags
    CREATE TABLE IF NOT EXISTS job_tags (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT UNIQUE NOT NULL,
        color TEXT DEFAULT '9e9e9e'
    );

    -- Job tag assignments
    CREATE TABLE IF NOT EXISTS job_tag_assignments (
        job_id INTEGER NOT NULL,
        tag_id INTEGER NOT NULL,
        PRIMARY KEY (job_id, tag_id),
        FOREIGN KEY (job_id) REFERENCES jobs(id) ON DELETE CASCADE,
        FOREIGN KEY (tag_id) REFERENCES job_tags(id) ON DELETE CASCADE
    );

    -- Job history
    CREATE TABLE IF NOT EXISTS job_history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        job_id TEXT NOT NULL,
        job_file TEXT,
        started_at TEXT NOT NULL,
        completed_at TEXT,
        total_devices INTEGER,
        success_count INTEGER,
        failed_count INTEGER,
        status TEXT,
        error_message TEXT
    );

    CREATE INDEX IF NOT EXISTS idx_job_history_started ON job_history(started_at);

    -- Captures (output file records)
    CREATE TABLE IF NOT EXISTS captures (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        device_id INTEGER,
        device_name TEXT NOT NULL,
        capture_type TEXT NOT NULL,
        filepath TEXT NOT NULL,
        file_size INTEGER,
        captured_at TEXT DEFAULT CURRENT_TIMESTAMP,
        job_history_id INTEGER,
        FOREIGN KEY (job_history_id) REFERENCES job_history(id)
    );

    CREATE INDEX IF NOT EXISTS idx_captures_device ON captures(device_name);
    CREATE INDEX IF NOT EXISTS idx_captures_type ON captures(capture_type);

    -- Views
    CREATE VIEW IF NOT EXISTS v_job_summary AS
    SELECT 
        j.id,
        j.name,
        j.slug,
        j.capture_type,
        j.vendor,
        j.is_enabled,
        j.last_run_at,
        j.last_run_status,
        j.schedule_enabled,
        j.schedule_cron,
        c.name AS credential_name,
        (SELECT COUNT(*) FROM job_history h WHERE h.job_id = j.slug OR h.job_id = CAST(j.legacy_job_id AS TEXT)) AS run_count,
        (SELECT MAX(started_at) FROM job_history h WHERE h.job_id = j.slug OR h.job_id = CAST(j.legacy_job_id AS TEXT)) AS last_history_run
    FROM jobs j
    LEFT JOIN credentials c ON j.credential_id = c.id;

    CREATE VIEW IF NOT EXISTS v_job_history_detail AS
    SELECT 
        h.*,
        j.name AS job_name,
        j.capture_type,
        j.vendor
    FROM job_history h
    LEFT JOIN jobs j ON h.job_id = j.slug OR h.job_id = CAST(j.legacy_job_id AS TEXT);
    """

    cursor.executescript(schema)
    conn.commit()
    conn.close()

    print(f"  ✓ {db_path}")
    print("    - credentials table (vault)")
    print("    - jobs table")
    print("    - job_history table")
    print("    - captures table")


def _init_tfsm_db(base_dir: Path):
    """Initialize TextFSM templates database."""
    import sqlite3

    db_path = base_dir / "tfsm_templates.db"

    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()

    # Check if already initialized
    cursor.execute("""
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name='templates'
    """)

    if cursor.fetchone() is not None:
        print(f"  - {db_path} (schema exists)")
        conn.close()
        return

    # Create schema
    schema = """
    CREATE TABLE IF NOT EXISTS templates (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT UNIQUE NOT NULL,
        template TEXT NOT NULL,
        description TEXT,
        platform TEXT,
        command TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
    );

    CREATE INDEX IF NOT EXISTS idx_templates_name ON templates(name);
    CREATE INDEX IF NOT EXISTS idx_templates_platform ON templates(platform);
    """

    cursor.executescript(schema)
    conn.commit()
    conn.close()

    print(f"  ✓ {db_path}")


def add_init_parser(subparsers):
    """Add init subparser to main parser."""
    init_parser = subparsers.add_parser(
        "init",
        help="Initialize VelocityCollector environment",
        description="Create directory structure and databases for a fresh installation",
    )

    init_parser.add_argument(
        "--dir", "-d",
        help="Base directory (default: ~/.vcollector)"
    )

    init_parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="Reinitialize even if already exists (WARNING: resets databases)"
    )

    init_parser.add_argument(
        "--no-defaults",
        action="store_true",
        help="Skip creating default platforms and roles"
    )

    init_parser.add_argument(
        "--skip-tfsm",
        action="store_true",
        help="Skip TextFSM templates database"
    )

    return init_parser